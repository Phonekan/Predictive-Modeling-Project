# -*- coding: utf-8 -*-
"""ProjectDX.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1p05hQh5si39wGoViinsarEjV2N6H0FsH
"""

from sklearn import datasets
import numpy as np
import pandas as pd

data = pd.read_csv ("/content/drive/MyDrive/holistic_health_lifestyle_dataset.csv")

data

print(data.shape)
print(data.columns)

# Missing Values

print("ตรวจสอบค่าว่างในแต่ละคอลัมน์ :\n" , data.isnull().sum())

# Encoding

from sklearn.preprocessing import LabelEncoder
le = LabelEncoder()
data["Health_Status"] = le.fit_transform(data["Health_Status"])

X = data[["Physical_Activity","Nutrition_Score","Stress_Level","Mindfulness","Sleep_Hours","Hydration","BMI","Smoking"]]
y = data["Health_Status"]

# การกระจายตัว

import matplotlib.pyplot as plt
import seaborn as sns

order = data["Health_Status"].value_counts().index

for i, v in enumerate(data["Health_Status"].value_counts()[order]):
    plt.text(i, v + 50, str(v), ha='center', fontsize=12, fontweight='bold', color='black')

plt.figure(figsize=(8,5))
sns.countplot(data=data, x="Health_Status", order=order, palette='coolwarm')

plt.title("Distribution of Health Status", fontsize=16, fontweight='bold')
plt.xlabel("Health_Status")
plt.ylabel("Number of Individuals")

sns.despine()
plt.show()

# train test
from sklearn.model_selection import train_test_split

X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.3, random_state=42 # test 30% , train 70%
)

# imbalanced
from sklearn.datasets import make_classification
from collections import Counter #นำเข้าเพื่อทำการนับข้อมูลที่เกิด imbalanced
import matplotlib.pyplot as plt
from imblearn.over_sampling import SMOTE

print("สัดส่วน Class ในชุดฝึกก่อน SMOTE:", Counter(y_train))

smote = SMOTE(random_state=42)
X_resampled, y_resampled = smote.fit_resample(X_train, y_train)

print("สัดส่วน Class ในชุดฝึกหลัง SMOTE:", Counter(y_resampled))

"""# Random Forest"""

from sklearn.metrics import classification_report, confusion_matrix, f1_score, accuracy_score
from sklearn.ensemble import RandomForestClassifier
import matplotlib.pyplot as plt
import seaborn as sns

rf = RandomForestClassifier(n_estimators=200, random_state=42) # Train Random Forest
rf.fit(X_resampled, y_resampled)

feature_imp = pd.Series(rf.feature_importances_, index=X.columns).sort_values(ascending=False)
feature_imp

importances = rf.feature_importances_ # Features importance values
features = X.columns

plt.figure(figsize=(8,6))
plt.bar(features, importances, color='purple')
plt.xlabel('Features')
plt.ylabel('Importances')
plt.title('Visualizing Important Features')
plt.xticks(rotation=45)
plt.tight_layout()
plt.show()

y_pred = rf.predict(X_test)

accuracy = accuracy_score(y_test, y_pred)
# ผลการประเมินโมเดล Random Forest Classifier
print(f"ความแม่นยำ (Accuracy): {accuracy:.2%}")

# รายงานการจำแนกประเภท (Classification Report)
print("\nรายงานผลการจำแนกประเภท (Classification Report):")
print(classification_report(y_test, y_pred, target_names=le.classes_))

print("=== Random Forest Performance ===")
print("Confusion Matrix :")
print(confusion_matrix(y_test, y_pred))

# --- Performance Measure ---
cm = confusion_matrix(y_test, y_pred)
plt.figure(figsize=(8, 6))
sns.heatmap(
    cm,
    annot=True,
    fmt='d',
    cmap='Blues',
    xticklabels=le.classes_,
    yticklabels=le.classes_,
)
plt.title('Confusion Matrix for Random Forest Classifier')
plt.ylabel('Actual Status')
plt.xlabel('Predicted Status')
plt.show()

"""# XGB"""

from xgboost import XGBClassifier
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, classification_report

xgb_optimal = XGBClassifier(
    n_estimators=300,        # ใช้ค่า Tuned
    learning_rate=0.05,      # ใช้ค่า Tuned
    max_depth=5,             # ใช้ค่า Tuned
    subsample=0.7,
    colsample_bytree=0.8,
    eval_metric='mlogloss',
    num_class = 3,           # สำหรับ Multiclass Classification

    random_state=42
)
# ฝึกโมเดลด้วยข้อมูลที่สมดุลแล้ว (X_resampled)
xgb_optimal.fit(X_resampled, y_resampled)

importances = xgb.feature_importances_
print("\n==== XGBoost Feature Importance ====")
for features, score in zip(X.columns, importances):
    print(f"{features}: {score:.4f}")

y_pred = xgb.predict(X_test)

accuracy = accuracy_score(y_test, y_pred)
print(f"Accuracy: {accuracy:.2%}")
print("\nClassification Report:\n", classification_report(y_test, y_pred, target_names=le.classes_))

plt.figure(figsize=(8,6))
sns.barplot(x=importances, y=X.columns)
plt.xlabel('Importance Score')
plt.ylabel('Features')
plt.title('XGBoost Features Importance')
plt.tight_layout()
plt.show()

print("=== XGB Performance ===")
print("Confusion Matrix :")
print(confusion_matrix(y_test, y_pred))

# --- Performance Measure ---
cm = confusion_matrix(y_test, y_pred)
plt.figure(figsize=(8, 6))
sns.heatmap(
    cm,
    annot=True,
    fmt='d',
    cmap='Blues',
    xticklabels=le.classes_,
    yticklabels=le.classes_,
)
plt.title('Confusion Matrix for XGB')
plt.ylabel('Actual Status')
plt.xlabel('Predicted Status')
plt.show()

important_cols = [
    'Mindfulness',
    'Nutrition_Score',
    'Smoking',
    'Sleep_Hours',
    'Health_Status']                                            # ต้องรวม target variable สำหรับ hue
data_subset = data[important_cols]
data_sampled = data_subset.sample(n=2000, random_state=42)                                 # 4. สุ่มตัวอย่างข้อมูล (Sampling) และสร้าง Pairplot

# Generate the focused pairplot
plt.figure(figsize=(10, 10))
sns.pairplot(
data_sampled, hue='Health_Status', palette='viridis',
    plot_kws={'alpha': 0.7, 's': 5},                           # ลดขนาดจุด (s) เหลือ 5 เพื่อแก้ปัญหา overplotting
    diag_kind='kde'
    )
plt.suptitle('Focused Pairplot of Top 4 Features by Health Status (2000 Samples)', y=1.02)
plt.show()